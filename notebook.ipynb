{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from skimage.segmentation import slic\n",
    "from skimage.future import graph\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import wnet_src.wnet as wnet\n",
    "import wnet_src.wnet as wnet\n",
    "import wnet_src.network as network\n",
    "import wnet_src.loss as loss\n",
    "from wnet_src.crf import crf_fit_predict, crf_batch_fit_predict\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an RGB representation of a segmentation mask using the mean color of each cluster\n",
    "def mask_to_rgb(mask, image):\n",
    "    mask_rgb = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "    for i in range(0, mask.max().astype(int)+1):\n",
    "        color = image[mask==i].mean(0)\n",
    "        mask_rgb[mask==i] = color\n",
    "    return np.round(mask_rgb).astype(np.uint8)\n",
    "\n",
    "# Saves segmentation mask as RGB image and CSV\n",
    "def save_segmentation(mask, image, method_name, id):\n",
    "    png_path = os.path.join(\"output\", method_name, \"png\", id + \".png\")\n",
    "    csv_path = os.path.join(\"output\", method_name, \"csv\", id + \".csv\")\n",
    "    os.makedirs(os.path.dirname(png_path), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    mask_rgb = mask_to_rgb(mask, image)\n",
    "    mask_rgb = Image.fromarray(mask_rgb)\n",
    "    mask_rgb.save(png_path)\n",
    "    np.savetxt(csv_path, mask, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate and Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSDS500_dir = 'BSDS500'\n",
    "gt_dir = os.path.join(BSDS500_dir, 'gt')\n",
    "test_image_dir = os.path.join(BSDS500_dir, 'BSDS500', 'data', 'images', 'test')\n",
    "test_image_paths = glob(os.path.join(test_image_dir, '*.jpg'))\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "class BSDS500_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, subset):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_paths = glob(os.path.join(root_dir, 'BSDS500', 'data', 'images', subset, '*.jpg'))\n",
    "        self.image_sizes = [np.take(torchvision.io.read_image(img_path).shape, [1,2]) for img_path in self.image_paths]\n",
    "        self.image_size = (224, 224)\n",
    "        \n",
    "        self.max_image = None\n",
    "        self.min_image = None\n",
    "        for i in range(self.__len__()):\n",
    "            image = torchvision.io.read_image(self.image_paths[i]).float()\n",
    "            image = torchvision.transforms.functional.resize(image, self.image_size, interpolation=torchvision.transforms.functional.InterpolationMode.BILINEAR)\n",
    "            self.max_image = torch.max(self.max_image, image) if self.max_image is not None else image\n",
    "            self.min_image = torch.min(self.min_image, image) if self.min_image is not None else image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def size(self, idx=None):\n",
    "        s = [self.__len__(), 3, self.image_size[0], self.image_size[1]]\n",
    "        if idx is not None:\n",
    "            s = s[idx]\n",
    "        else:\n",
    "            s = torch.Size(s)\n",
    "        return s\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = torchvision.io.read_image(img_path)\n",
    "        image = image.float()\n",
    "        image = torchvision.transforms.functional.resize(image, self.image_size, interpolation=torchvision.transforms.functional.InterpolationMode.BILINEAR)\n",
    "        image = (image - self.min_image) / (self.max_image - self.min_image)\n",
    "        return image.to(device)\n",
    "\n",
    "class BSDS500():\n",
    "    def __init__(self, root_dir, batch_size):\n",
    "        self.trainset = BSDS500_dataset(root_dir, 'train')\n",
    "        self.trainloader = torch.utils.data.DataLoader(self.trainset, batch_size=batch_size, shuffle=True)\n",
    "        self.valset = BSDS500_dataset(root_dir, 'val')\n",
    "        self.valloader = torch.utils.data.DataLoader(self.valset, batch_size=batch_size, shuffle=False)\n",
    "        self.testset = BSDS500_dataset(root_dir, 'test')\n",
    "        self.testloader = torch.utils.data.DataLoader(self.testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    def get_trainloader(self):\n",
    "        return self.trainloader\n",
    "    \n",
    "    def get_valloader(self):\n",
    "        return self.valloader\n",
    "\n",
    "    def get_testloader(self):\n",
    "        return self.testloader\n",
    "\n",
    "if device == \"mps\":\n",
    "    batch_size = 16\n",
    "else:\n",
    "    batch_size = 8\n",
    "\n",
    "bsds = BSDS500('../BSDS500', batch_size)\n",
    "X_train = bsds.get_trainloader()\n",
    "y_train = bsds.get_trainloader()\n",
    "X_val = bsds.get_valloader()\n",
    "y_val = bsds.get_valloader()\n",
    "X_test = bsds.get_testloader()\n",
    "y_test = bsds.get_testloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Segmentation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run K-Means on HSV encoded images\n",
    "for path in tqdm(test_image_paths):\n",
    "    # Load image\n",
    "    id = os.path.splitext(os.path.basename(path))[0]\n",
    "    imageRGB = Image.open(path)\n",
    "    image = np.array(imageRGB.convert(\"HSV\"))\n",
    "    pixels = image.reshape((-1, 3)) # Reshape to 2D array of pixels\n",
    "    segmentors = []\n",
    "    sils = []\n",
    "    # Try k in range 3 to 17 with step size 2\n",
    "    for k in range(3,17,2):\n",
    "        segmentor = KMeans(n_clusters=k, random_state=0, init=\"random\")\n",
    "        segmentor.fit(pixels)\n",
    "        segmentors.append(segmentor)\n",
    "        sil = silhouette_score(pixels, segmentor.labels_, sample_size=5000) # Calculate silhouette score of clustering\n",
    "        sils.append(sil)\n",
    "        if len(sils) >= 3 and sils[-1] < sils[-2] and sils[-2] < sils[-3]: # Terminate search if silhouette score is decreasing\n",
    "            break\n",
    "    segmentor = segmentors[np.argmax(sils)] # Choose segmentor with highest silhouette score\n",
    "    mask = segmentor.labels_.reshape(image.shape[:2]) # Match shape of image\n",
    "\n",
    "    save_segmentation(mask, np.array(imageRGB), \"KMeans\", id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:18<00:00,  9.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run EM on HSV encoded images\n",
    "for path in tqdm(test_image_paths):\n",
    "    # Load image\n",
    "    id = os.path.splitext(os.path.basename(path))[0]\n",
    "    imageRGB = Image.open(path)\n",
    "    image = np.array(imageRGB.convert(\"HSV\"))\n",
    "    pixels = image.reshape((-1, 3)) # Reshape to 2D array of pixels\n",
    "    segmentors = []\n",
    "    sils = []\n",
    "    # Try k in range 3 to 17 with step size 2\n",
    "    for k in range(3,17,2):\n",
    "        segmentor = GaussianMixture(n_components=k, random_state=0)\n",
    "        segmentor.fit(pixels)\n",
    "        segmentors.append(segmentor)\n",
    "        sil = silhouette_score(pixels, segmentor.predict(pixels), sample_size=5000) # Calculate silhouette score of clustering\n",
    "        sils.append(sil)\n",
    "        if len(sils) >= 3 and sils[-1] < sils[-2] and sils[-2] < sils[-3]: # Terminate search if silhouette score is decreasing\n",
    "            break\n",
    "    segmentor = segmentors[np.argmax(sils)] # Choose segmentor with highest silhouette score\n",
    "    mask = segmentor.predict(pixels).reshape(image.shape[:2]) # Match shape of image\n",
    "\n",
    "    save_segmentation(mask, np.array(imageRGB), \"EM\", id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/zc/s2x1jcqx7gd7y6myf0gmt49c0000gn/T/ipykernel_61655/240538252.py:7: RuntimeWarning: Mean of empty slice.\n",
      "  color = image[mask==i].mean(0)\n",
      "/Users/isaac/miniforge3/lib/python3.9/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "100%|██████████| 2/2 [00:16<00:00,  8.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run normalized cuts on RGB images\n",
    "for path in tqdm(test_image_paths[:2]):\n",
    "    # Load image\n",
    "    id = os.path.splitext(os.path.basename(path))[0]\n",
    "    image = np.array(Image.open(path))\n",
    "\n",
    "    # Run 400-means on image in RGBXY space\n",
    "    labels = slic(image, compactness=30, n_segments=400)\n",
    "    # Assemble region adjacency graph\n",
    "    g = graph.rag_mean_color(image, labels, mode='similarity')\n",
    "    # Run normalized cuts\n",
    "    labels = graph.cut_normalized(labels, g)\n",
    "    \n",
    "    save_segmentation(labels, image, \"NormalizedCuts\", id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W-Net [Xia and Kulis (2017)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from wnet-2022-12-02-02-50.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [03:43<00:00, 17.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# Implementation based on https://github.com/fkodom/wnet-unsupervised-image-segmentation\n",
    "\n",
    "# Configure\n",
    "train = False\n",
    "epochs = 500\n",
    "use_checkpoint = True\n",
    "checkpoint_path = 'wnet-2022-12-02-02-50.pt'\n",
    "\n",
    "net = wnet.WNet(device_type=device)\n",
    "net.to(device)\n",
    "if use_checkpoint:\n",
    "    # Load checkpoint from previous training for 500 epochs\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    net.to(device)\n",
    "    print('Loaded checkpoint from {}'.format(checkpoint_path))\n",
    "\n",
    "if train:\n",
    "    net.fit(\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        epochs=epochs,\n",
    "        learn_rate=1e-3,\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "    date = datetime.now().__str__()\n",
    "    date = date[:16].replace(':', '-').replace(' ', '-')\n",
    "    torch.save({'epoch': epochs, 'model_state_dict': net.state_dict()}, f'models/wnet-{date}.pt')\n",
    "\n",
    "# Run WNet on test images\n",
    "all_inputs = []\n",
    "all_masks = []\n",
    "for i,batch in tqdm(enumerate(X_test), total=len(X_test)):\n",
    "    inputs = batch\n",
    "    mask, outputs = net.forward(inputs)\n",
    "    inputs = inputs.detach().cpu().numpy()\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    mask = mask.detach().cpu().numpy()\n",
    "    # Post process encoded images with conditional random field\n",
    "    crf_mask = crf_batch_fit_predict(mask, inputs)\n",
    "    for j in range(inputs.shape[0]):\n",
    "        all_masks.append(crf_mask[j])\n",
    "\n",
    "# Save results\n",
    "for i,mask in tqdm(enumerate(all_masks), total=len(all_masks)):\n",
    "    image_path = bsds.testset.image_paths[i]\n",
    "    id = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    image = np.array(Image.open(image_path))\n",
    "    mask = torchvision.transforms.functional.resize(torch.tensor(mask), list(bsds.testset.image_sizes[i]), interpolation=torchvision.transforms.functional.InterpolationMode.NEAREST)\n",
    "    mask = np.array(mask.argmax(0))\n",
    "    save_segmentation(mask, image, \"WNet\", id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiable Feature Clustering [Kim, Kanezaki, and Tanaka (2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation based on https://github.com/kanezaki/pytorch-unsupervised-segmentation-tip\n",
    "\n",
    "# Configure\n",
    "args = {\n",
    "    \"scribble\": False,\n",
    "    \"nChannel\": 100,\n",
    "    \"maxIter\": 50,\n",
    "    \"minLabels\": 3,\n",
    "    \"lr\": 0.1,\n",
    "    \"nConv\": 2,\n",
    "    \"visualize\": 1,\n",
    "    \"input\": None,\n",
    "    \"stepsize_sim\": 1,\n",
    "    \"stepsize_con\": 1,\n",
    "    \"stepsize_scr\": 0.5\n",
    "}\n",
    "\n",
    "# Define model architecture\n",
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(input_dim, args[\"nChannel\"], kernel_size=3, stride=1, padding=1 )\n",
    "        self.bn1 = torch.nn.BatchNorm2d(args[\"nChannel\"])\n",
    "        self.conv2 = torch.nn.ModuleList()\n",
    "        self.bn2 = torch.nn.ModuleList()\n",
    "        for i in range(args[\"nConv\"]-1):\n",
    "            self.conv2.append( torch.nn.Conv2d(args[\"nChannel\"], args[\"nChannel\"], kernel_size=3, stride=1, padding=1 ) )\n",
    "            self.bn2.append( torch.nn.BatchNorm2d(args[\"nChannel\"]) )\n",
    "        self.conv3 = torch.nn.Conv2d(args[\"nChannel\"], args[\"nChannel\"], kernel_size=1, stride=1, padding=0 )\n",
    "        self.bn3 = torch.nn.BatchNorm2d(args[\"nChannel\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu( x )\n",
    "        x = self.bn1(x)\n",
    "        for i in range(args[\"nConv\"]-1):\n",
    "            x = self.conv2[i](x)\n",
    "            x = torch.nn.functional.relu( x )\n",
    "            x = self.bn2[i](x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        return x\n",
    "\n",
    "# Define segmentation function\n",
    "def dfc_segment(image_path):\n",
    "    # Load image\n",
    "    im = np.array(Image.open(image_path))\n",
    "    data = torch.from_numpy( np.array([im.transpose( (2, 0, 1) ).astype('float32')/255.]) ).to(device)\n",
    "\n",
    "    # Instantiate model\n",
    "    model = MyNet(data.size(1)).to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Define loss functions\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    # continuity loss definition\n",
    "    loss_hpy = torch.nn.L1Loss(size_average = True).to(device)\n",
    "    loss_hpz = torch.nn.L1Loss(size_average = True).to(device)\n",
    "    HPy_target = torch.zeros(im.shape[0]-1, im.shape[1], args[\"nChannel\"]).to(device)\n",
    "    HPz_target = torch.zeros(im.shape[0], im.shape[1]-1, args[\"nChannel\"]).to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args[\"lr\"], momentum=0.9)\n",
    "\n",
    "    # Train on image\n",
    "    for i in range(args[\"maxIter\"]):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        output = model( data )[ 0 ]\n",
    "        output = output.permute( 1, 2, 0 ).contiguous().view( -1, args[\"nChannel\"] )\n",
    "\n",
    "        # calculate continuity loss\n",
    "        outputHP = output.reshape( (im.shape[0], im.shape[1], args[\"nChannel\"]) )\n",
    "        HPy = outputHP[1:, :, :] - outputHP[0:-1, :, :]\n",
    "        HPz = outputHP[:, 1:, :] - outputHP[:, 0:-1, :]\n",
    "        lhpy = loss_hpy(HPy.to(device),HPy_target.to(device))\n",
    "        lhpz = loss_hpz(HPz.to(device),HPz_target.to(device))\n",
    "\n",
    "        # calculate similarity loss\n",
    "        ignore, target = torch.max( output, 1 )\n",
    "        im_target = target.data.cpu().numpy()\n",
    "        nLabels = len(np.unique(im_target))\n",
    "        loss = args[\"stepsize_sim\"] * loss_fn(output, target) + args[\"stepsize_con\"] * (lhpy + lhpz)\n",
    "\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # terminate if the number of labels is less than minLabels\n",
    "        if nLabels <= args[\"minLabels\"]:\n",
    "            print (\"nLabels\", nLabels, \"reached minLabels\", args[\"minLabels\"], \".\")\n",
    "            break\n",
    "    \n",
    "    output = model( data )[ 0 ]\n",
    "    output = output.permute( 1, 2, 0 ).contiguous().view( -1, args[\"nChannel\"] )\n",
    "    ignore, target = torch.max( output, 1 )\n",
    "    im_target = target.data.cpu().numpy()\n",
    "\n",
    "    return im,target.data.cpu().numpy().reshape( im.shape[:2] ).astype( np.uint8 )\n",
    "\n",
    "# Run segmentation\n",
    "for i,image_path in tqdm(enumerate(test_image_paths), total=len(test_image_paths)):\n",
    "    id = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    image, mask = dfc_segment(image_path)\n",
    "    save_segmentation(mask, image, \"DFC\", id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]/var/folders/zc/s2x1jcqx7gd7y6myf0gmt49c0000gn/T/ipykernel_62073/3422155633.py:5: RuntimeWarning: Mean of empty slice.\n",
      "  color = image[mask==i].mean(0)\n",
      "100%|██████████| 200/200 [35:24<00:00, 10.62s/it]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 29030\n",
    "\n",
    "segmentation_masks = {os.path.split(path)[1]: np.loadtxt(path, delimiter=',') for path in glob(f'output/*/csv/{id}.csv')}\n",
    "segmentation_images = {os.path.split(path)[1]: np.array(Image.open(path)) for path in glob(f'output/*/png/{id}.png')}\n",
    "\n",
    "# def ensemble_bagging(segmentations):\n",
    "#     segmentations_categorical = []\n",
    "#     for segmentation in segmentations:\n",
    "#         segmentation = np.array(segmentation)\n",
    "#         segmentation_categorical = np.zeros(segmentation.shape[0:2])\n",
    "#         colors = np.unique(segmentation.reshape(-1, segmentation.shape[2]), axis=0)\n",
    "#         for i, color in enumerate(colors):\n",
    "#             segmentation_categorical[(segmentation == color).all(axis=2)] = i\n",
    "#         segmentations_categorical.append(segmentation_categorical)\n",
    "\n",
    "#     stack = np.dstack(segmentations_categorical)\n",
    "#     hyper_colors = np.unique(stack.reshape(-1, stack.shape[2]), axis=0)\n",
    "#     hyper_image = np.zeros(stack.shape[0:2])\n",
    "#     for i, color in enumerate(hyper_colors):\n",
    "#         hyper_image[(stack == color).all(axis=2)] = i\n",
    "#     return hyper_image\n",
    "\n",
    "# def ensemble_stacking(base_segmentation):\n",
    "#     base_segmentation = np.array(base_segmentation)\n",
    "#     labels = slic(base_segmentation, compactness=30, n_segments=400)\n",
    "#     g = graph.rag_mean_color(base_segmentation, labels, mode='similarity')\n",
    "#     labels = graph.cut_normalized(labels, g)\n",
    "#     return labels\n",
    "\n",
    "# def mask_to_rgb(mask, image):\n",
    "#     mask_rgb = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "#     for i in range(0, mask.max().astype(int)+1):\n",
    "#         color = image[mask==i].mean(0)\n",
    "#         mask_rgb[mask==i] = color\n",
    "#     return np.round(mask_rgb).astype(np.uint8)\n",
    "\n",
    "# hyper_segmentation = ensemble_stacking(wnet)\n",
    "# hyper_segmentation = mask_to_rgb(hyper_segmentation, np.array(original))\n",
    "\n",
    "# # make 3x2 subplot grid\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(5, 5))\n",
    "# # display images in each subplot\n",
    "# axes[0, 0].imshow(kmeans)\n",
    "# axes[0, 1].imshow(em)\n",
    "# axes[0, 2].imshow(ncut)\n",
    "# axes[1, 0].imshow(wnet)\n",
    "# axes[1, 1].imshow(dfc)\n",
    "# axes[1, 2].imshow(hyper_segmentation)\n",
    "# # remove axis ticks\n",
    "# for ax in axes.flat:\n",
    "#     ax.set(xticks=[], yticks=[])\n",
    "# # add titles\n",
    "# axes[0, 0].set_title('K-Means')\n",
    "# axes[0, 1].set_title('EM')\n",
    "# axes[0, 2].set_title('NCuts')\n",
    "# axes[1, 0].set_title('WNet')\n",
    "# axes[1, 1].set_title('DFC')\n",
    "# axes[1, 2].set_title('Ensemble')\n",
    "# # show the figure\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# mIOU = evaluation.calculate_mIOU\n",
    "# VI = evaluation.calculate_VI\n",
    "# PRI = evaluation.calculate_PRI\n",
    "# SC = evaluation.calculate_segmentation_covering\n",
    "\n",
    "# kmeans_score = mIOU(np.array(kmeans), id) + VI(np.array(kmeans), id) + PRI(np.array(kmeans), id) + SC(np.array(kmeans), id)\n",
    "# em_score = mIOU(np.array(em), id) + VI(np.array(em), id) + PRI(np.array(em), id) + SC(np.array(em), id)\n",
    "# ncut_score = mIOU(np.array(ncut), id) + VI(np.array(ncut), id) + PRI(np.array(ncut), id) + SC(np.array(ncut), id)\n",
    "# wnet_score = mIOU(np.array(wnet), id) + VI(np.array(wnet), id) + PRI(np.array(wnet), id) + SC(np.array(wnet), id)\n",
    "# dfc_score = mIOU(np.array(dfc), id) + VI(np.array(dfc), id) + PRI(np.array(dfc), id) + SC(np.array(dfc), id)\n",
    "# ensemble_score = mIOU(hyper_segmentation, id) + VI(np.array(hyper_segmentation), id) + PRI(np.array(hyper_segmentation), id) + SC(np.array(hyper_segmentation), id)\n",
    "\n",
    "# scores = np.array([kmeans_score, em_score, ncut_score, wnet_score, dfc_score, ensemble_score])\n",
    "\n",
    "# def plot_scores(methods, scores, title, score_names, ylabel, colors):\n",
    "#     x = np.arange(len(methods))\n",
    "#     width = 0.35\n",
    "#     fig, ax = plt.subplots()\n",
    "#     rects1 = ax.bar(x - width/2, scores[:,0], width, label=score_names[0], color=colors[0])\n",
    "#     rects2 = ax.bar(x + width/2, scores[:,1], width, label=score_names[1], color=colors[1])\n",
    "#     ax.set_ylabel(ylabel)\n",
    "#     ax.set_title(title)\n",
    "#     ax.set_xticks(x, methods)\n",
    "#     ax.legend()\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "\n",
    "# plot_scores(\n",
    "#     ['K-Means', 'EM', 'NCuts', 'WNet', 'DFC', 'Ensemble'],\n",
    "#     scores[:,:2],\n",
    "#     'mIOU scores per method (higher is better)',\n",
    "#     ['Mean mIOU', 'Max mIOU'],\n",
    "#     'mIOU',\n",
    "#     ['tab:blue', 'tab:green']\n",
    "#     )\n",
    "# plot_scores(\n",
    "#     ['K-Means', 'EM', 'NCuts', 'WNet', 'DFC', 'Ensemble'],\n",
    "#     scores[:,2:4],\n",
    "#     'VI scores per method (lower is better)',\n",
    "#     ['Mean VI', 'Max VI'],\n",
    "#     'Variation of Information',\n",
    "#     ['tab:pink', 'tab:red']\n",
    "#     )\n",
    "# plot_scores(\n",
    "#     ['K-Means', 'EM', 'NCuts', 'WNet', 'DFC', 'Ensemble'],\n",
    "#     scores[:,4:6],\n",
    "#     'PRI scores per method (higher is better)',\n",
    "#     ['Mean PRI', 'Max PRI'],\n",
    "#     'Probabilistic Rand Index',\n",
    "#     ['tab:purple', 'tab:orange']\n",
    "#     )\n",
    "# plot_scores(\n",
    "#     ['K-Means', 'EM', 'NCuts', 'WNet', 'DFC', 'Ensemble'],\n",
    "#     scores[:,6:8],\n",
    "#     'SC scores per method (higher is better)',\n",
    "#     ['Mean SC', 'Max SC'],\n",
    "#     'Segmentation Covering',\n",
    "#     ['tab:brown', 'tab:gray']\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "394d24a1087ab98538c556b121a84e46182f365585e86aa7ee7d846ee7e5fae4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
