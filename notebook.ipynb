{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from skimage.segmentation import slic\n",
    "from skimage.future import graph\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import wnet_src.wnet as wnet\n",
    "import wnet_src.wnet as wnet\n",
    "import wnet_src.network as network\n",
    "import wnet_src.loss as loss\n",
    "from wnet_src.crf import crf_fit_predict, crf_batch_fit_predict\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an RGB representation of a segmentation mask using the mean color of each cluster\n",
    "def mask_to_rgb(mask, image):\n",
    "    mask_rgb = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "    for i in range(0, mask.max().astype(int)+1):\n",
    "        color = image[mask==i].mean(0)\n",
    "        mask_rgb[mask==i] = color\n",
    "    return np.round(mask_rgb).astype(np.uint8)\n",
    "\n",
    "# Saves segmentation mask as RGB image and CSV\n",
    "def save_segmentation(mask, image, method_name, id):\n",
    "    png_path = os.path.join(\"output\", method_name, \"png\", id + \".png\")\n",
    "    csv_path = os.path.join(\"output\", method_name, \"csv\", id + \".csv\")\n",
    "    os.makedirs(os.path.dirname(png_path), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    mask_rgb = mask_to_rgb(mask, image)\n",
    "    mask_rgb = Image.fromarray(mask_rgb)\n",
    "    mask_rgb.save(png_path)\n",
    "    np.savetxt(csv_path, mask, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate and Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSDS500_dir = 'BSDS500'\n",
    "gt_dir = os.path.join(BSDS500_dir, 'gt')\n",
    "test_image_dir = os.path.join(BSDS500_dir, 'BSDS500', 'data', 'images', 'test')\n",
    "test_image_paths = glob(os.path.join(test_image_dir, '*.jpg'))\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "class BSDS500_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, subset):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_paths = glob(os.path.join(root_dir, 'BSDS500', 'data', 'images', subset, '*.jpg'))\n",
    "        self.image_sizes = [np.take(torchvision.io.read_image(img_path).shape, [1,2]) for img_path in self.image_paths]\n",
    "        self.image_size = (224, 224)\n",
    "        \n",
    "        self.max_image = None\n",
    "        self.min_image = None\n",
    "        for i in range(self.__len__()):\n",
    "            image = torchvision.io.read_image(self.image_paths[i]).float()\n",
    "            image = torchvision.transforms.functional.resize(image, self.image_size, interpolation=torchvision.transforms.functional.InterpolationMode.BILINEAR)\n",
    "            self.max_image = torch.max(self.max_image, image) if self.max_image is not None else image\n",
    "            self.min_image = torch.min(self.min_image, image) if self.min_image is not None else image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def size(self, idx=None):\n",
    "        s = [self.__len__(), 3, self.image_size[0], self.image_size[1]]\n",
    "        if idx is not None:\n",
    "            s = s[idx]\n",
    "        else:\n",
    "            s = torch.Size(s)\n",
    "        return s\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = torchvision.io.read_image(img_path)\n",
    "        image = image.float()\n",
    "        image = torchvision.transforms.functional.resize(image, self.image_size, interpolation=torchvision.transforms.functional.InterpolationMode.BILINEAR)\n",
    "        image = (image - self.min_image) / (self.max_image - self.min_image)\n",
    "        return image.to(device)\n",
    "\n",
    "class BSDS500():\n",
    "    def __init__(self, root_dir, batch_size):\n",
    "        self.trainset = BSDS500_dataset(root_dir, 'train')\n",
    "        self.trainloader = torch.utils.data.DataLoader(self.trainset, batch_size=batch_size, shuffle=True)\n",
    "        self.valset = BSDS500_dataset(root_dir, 'val')\n",
    "        self.valloader = torch.utils.data.DataLoader(self.valset, batch_size=batch_size, shuffle=False)\n",
    "        self.testset = BSDS500_dataset(root_dir, 'test')\n",
    "        self.testloader = torch.utils.data.DataLoader(self.testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    def get_trainloader(self):\n",
    "        return self.trainloader\n",
    "    \n",
    "    def get_valloader(self):\n",
    "        return self.valloader\n",
    "\n",
    "    def get_testloader(self):\n",
    "        return self.testloader\n",
    "\n",
    "if device == \"mps\":\n",
    "    batch_size = 16\n",
    "else:\n",
    "    batch_size = 8\n",
    "\n",
    "bsds = BSDS500('../BSDS500', batch_size)\n",
    "X_train = bsds.get_trainloader()\n",
    "y_train = bsds.get_trainloader()\n",
    "X_val = bsds.get_valloader()\n",
    "y_val = bsds.get_valloader()\n",
    "X_test = bsds.get_testloader()\n",
    "y_test = bsds.get_testloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Segmentation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run K-Means on HSV encoded images\n",
    "for path in tqdm(test_image_paths):\n",
    "    # Load image\n",
    "    id = os.path.splitext(os.path.basename(path))[0]\n",
    "    imageRGB = Image.open(path)\n",
    "    image = np.array(imageRGB.convert(\"HSV\"))\n",
    "    pixels = image.reshape((-1, 3)) # Reshape to 2D array of pixels\n",
    "    segmentors = []\n",
    "    sils = []\n",
    "    # Try k in range 3 to 17 with step size 2\n",
    "    for k in range(3,17,2):\n",
    "        segmentor = KMeans(n_clusters=k, random_state=0, init=\"random\")\n",
    "        segmentor.fit(pixels)\n",
    "        segmentors.append(segmentor)\n",
    "        sil = silhouette_score(pixels, segmentor.labels_, sample_size=5000) # Calculate silhouette score of clustering\n",
    "        sils.append(sil)\n",
    "        if len(sils) >= 3 and sils[-1] < sils[-2] and sils[-2] < sils[-3]: # Terminate search if silhouette score is decreasing\n",
    "            break\n",
    "    segmentor = segmentors[np.argmax(sils)] # Choose segmentor with highest silhouette score\n",
    "    mask = segmentor.labels_.reshape(image.shape[:2]) # Match shape of image\n",
    "\n",
    "    save_segmentation(mask, np.array(imageRGB), \"KMeans\", id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:18<00:00,  9.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run EM on HSV encoded images\n",
    "for path in tqdm(test_image_paths):\n",
    "    # Load image\n",
    "    id = os.path.splitext(os.path.basename(path))[0]\n",
    "    imageRGB = Image.open(path)\n",
    "    image = np.array(imageRGB.convert(\"HSV\"))\n",
    "    pixels = image.reshape((-1, 3)) # Reshape to 2D array of pixels\n",
    "    segmentors = []\n",
    "    sils = []\n",
    "    # Try k in range 3 to 17 with step size 2\n",
    "    for k in range(3,17,2):\n",
    "        segmentor = GaussianMixture(n_components=k, random_state=0)\n",
    "        segmentor.fit(pixels)\n",
    "        segmentors.append(segmentor)\n",
    "        sil = silhouette_score(pixels, segmentor.predict(pixels), sample_size=5000) # Calculate silhouette score of clustering\n",
    "        sils.append(sil)\n",
    "        if len(sils) >= 3 and sils[-1] < sils[-2] and sils[-2] < sils[-3]: # Terminate search if silhouette score is decreasing\n",
    "            break\n",
    "    segmentor = segmentors[np.argmax(sils)] # Choose segmentor with highest silhouette score\n",
    "    mask = segmentor.predict(pixels).reshape(image.shape[:2]) # Match shape of image\n",
    "\n",
    "    save_segmentation(mask, np.array(imageRGB), \"EM\", id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/var/folders/zc/s2x1jcqx7gd7y6myf0gmt49c0000gn/T/ipykernel_61655/240538252.py:7: RuntimeWarning: Mean of empty slice.\n",
      "  color = image[mask==i].mean(0)\n",
      "/Users/isaac/miniforge3/lib/python3.9/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "100%|██████████| 2/2 [00:16<00:00,  8.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run normalized cuts on RGB images\n",
    "for path in tqdm(test_image_paths[:2]):\n",
    "    # Load image\n",
    "    id = os.path.splitext(os.path.basename(path))[0]\n",
    "    image = np.array(Image.open(path))\n",
    "\n",
    "    # Run 400-means on image in RGBXY space\n",
    "    labels = slic(image, compactness=30, n_segments=400)\n",
    "    # Assemble region adjacency graph\n",
    "    g = graph.rag_mean_color(image, labels, mode='similarity')\n",
    "    # Run normalized cuts\n",
    "    labels = graph.cut_normalized(labels, g)\n",
    "    \n",
    "    save_segmentation(labels, image, \"NormalizedCuts\", id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from wnet-2022-12-02-02-50.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [03:43<00:00, 17.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# Confugre\n",
    "train = False\n",
    "epochs = 500\n",
    "use_checkpoint = True\n",
    "checkpoint_path = 'wnet-2022-12-02-02-50.pt'\n",
    "\n",
    "net = wnet.WNet(device_type=device)\n",
    "net.to(device)\n",
    "if use_checkpoint:\n",
    "    # Load checkpoint from previous training for 500 epochs\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    net.to(device)\n",
    "    print('Loaded checkpoint from {}'.format(checkpoint_path))\n",
    "\n",
    "if train:\n",
    "    net.fit(\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        epochs=epochs,\n",
    "        learn_rate=1e-3,\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "    date = datetime.now().__str__()\n",
    "    date = date[:16].replace(':', '-').replace(' ', '-')\n",
    "    torch.save({'epoch': epochs, 'model_state_dict': net.state_dict()}, f'models/wnet-{date}.pt')\n",
    "\n",
    "# Run WNet on test images\n",
    "all_inputs = []\n",
    "all_masks = []\n",
    "for i,batch in tqdm(enumerate(X_test), total=len(X_test)):\n",
    "    inputs = batch\n",
    "    mask, outputs = net.forward(inputs)\n",
    "    inputs = inputs.detach().cpu().numpy()\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    mask = mask.detach().cpu().numpy()\n",
    "    # Post process encoded images with conditional random field\n",
    "    crf_mask = crf_batch_fit_predict(mask, inputs)\n",
    "    for j in range(inputs.shape[0]):\n",
    "        all_masks.append(crf_mask[j])\n",
    "\n",
    "# Save results\n",
    "for i,mask in tqdm(enumerate(all_masks), total=len(all_masks)):\n",
    "    image_path = bsds.testset.image_paths[i]\n",
    "    id = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    image = np.array(Image.open(image_path))\n",
    "    mask = torchvision.transforms.functional.resize(torch.tensor(mask), list(bsds.testset.image_sizes[i]), interpolation=torchvision.transforms.functional.InterpolationMode.NEAREST)\n",
    "    mask = np.array(mask.argmax(0))\n",
    "    save_segmentation(mask, image, \"WNet\", id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "394d24a1087ab98538c556b121a84e46182f365585e86aa7ee7d846ee7e5fae4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
